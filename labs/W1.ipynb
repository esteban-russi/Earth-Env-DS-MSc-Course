{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W1: Review of Python: NumPy, Pandas, and Basic Operation of Environmental Datasets\n",
    "\n",
    "- Contributers: Dr. Zhonghua Zheng, Yuan Sun\n",
    "- Course Unit: Earth and Environmental Data Science (EART60702)\n",
    "- Last modified date: 29 January, 2024\n",
    "\n",
    "## Intended Learning Outcomes (ILOs)\n",
    "- Numpy Array Proficiency: learn to create and manipulate Numpy arrays, understanding both one-dimensional and multi-dimensional array operations.\n",
    "- Data Handling with Pandas: gain skills in importing, exporting, and manipulating data using Pandas DataFrames.\n",
    "- Environmental Data Analysis: apply Numpy and Pandas skills to analyze environmental datasets and use these analyses in a project context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numpy (15 mins)\n",
    "- NumPy (Numerical Python) is the fundamental package for scientific computing in Python: https://numpy.org/doc/stable/.\n",
    "\n",
    "- NumPy is an open source Python library that’s used in almost every field of science and engineering. It’s the universal standard for working with numerical data in Python, and it’s at the core of the scientific Python and PyData ecosystems: https://numpy.org/doc/stable/user/absolute_beginners.html.\n",
    "\n",
    "- NumPy can be used to perform a wide variety of mathematical operations on **arrays**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check numpy version\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ways to create a numpy 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way1\n",
    "a = np.array([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way2\n",
    "b = np.zeros(2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way3\n",
    "c = np.ones(2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way4\n",
    "d = np.arange(4)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to specify the dtype as float, int, etc\n",
    "# search more details on how to use np.arange() in : https://numpy.org/doc/stable/reference/generated/numpy.arange.html#numpy-arange\n",
    "d_f = np.arange(4, dtype=float)\n",
    "d_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way5\n",
    "e = np.arange(2, 9, 2)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way6\n",
    "f = np.linspace(0, 10, num=5)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# way7: create an array from existing data\n",
    "a0 = np.array([1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
    "a1 = a0[3:8]\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 2-D or Muti-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1D = np.array([1, 2, 3, 4])\n",
    "a2D = np.array([[1, 2], [3, 4]])\n",
    "a3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "\n",
    "a3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 basic array operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.array([1, 2])\n",
    "d2 = np.ones(2, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addition\n",
    "d1 + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substraction\n",
    "d1 - d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "d1 * 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum\n",
    "d1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max\n",
    "d1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min\n",
    "d1.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- the product operator `*` operates elementwise in NumPy arrays\n",
    "- the matrix product can be performed using the `@` operator (in python >=3.5) or the `dot` function or method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "b = np.array([[4, 1],\n",
    "              [2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Pandas (15 mins)\n",
    "- pandas is a Python package providing fast, flexible, and expressive data structures designed to make working with \"relational\" or \"labeled\" data both easy and intuitive: https://pandas.pydata.org/docs/getting_started/overview.html\n",
    "- When working with tabular data, such as data stored in spreadsheets or databases, pandas is the right tool for you. pandas will help you to explore, clean, and process your data. In pandas, a data table is called a `DataFrame`.\n",
    "- The two primary data structures of pandas, `Series` (1-dimensional) and `DataFrame` (2-dimensional), handle the vast majority of typical use cases in finance, statistics, social science, and many areas of engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check pandas version\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 importing and exporting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here let's learn how create a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a datafrme like a dictionary\n",
    "df0 = pd.DataFrame(\n",
    "    {\"A\": 1.0,\n",
    "     \"B\": pd.Timestamp(\"20240128\"),\n",
    "     \"C\": pd.Series(1, index=list(range(4)), dtype = float),\n",
    "     \"D\": pd.Categorical([\"test\", \"train\",\"foo\",\"test\"])\n",
    "     }\n",
    ")\n",
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe from a numpy array\n",
    "a = np.array([[-2.58289208,  0.43014843, -1.24082018, 1.59572603],\n",
    "              [ 0.99027828, 1.17150989,  0.94125714, -0.14692469],\n",
    "              [ 0.76989341,  0.81299683, -0.95068423, 0.11769564],\n",
    "              [ 0.20484034,  0.34784527,  1.96979195, 0.51992837]])\n",
    "\n",
    "df = pd.DataFrame(a)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export a dataframe to a csv file. Why `index=False`? https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv(\"foo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the csv file that we exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a CSV\n",
    "# you should upload a csv \n",
    "df1 = pd.read_csv('foo.csv')\n",
    "\n",
    "# if you want to specify the path\n",
    "# path = 'XXX/XXX/XXX/XXX'\n",
    "# df.to_csv(path + 'pd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Manipulating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the dataframe column\n",
    "name = ['first_column', 'second_column', 'third_column', 'fourth_column']\n",
    "df2 = pd.DataFrame(a, columns = name)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column to an existing dataframe\n",
    "df2['fifth_column'] = ['Hi', 'Hello', 'bonjour', 'nihao']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a specific column, where each column is a series\n",
    "df2_first_column = df2['first_column']\n",
    "df2_first_column.head() # df2_first_column is a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select more than one column\n",
    "df2_multi_column = df2[['first_column', 'third_column']]\n",
    "\n",
    "df2_multi_column.head() # df2_multi_column is a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# know the shape of a dataframe\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows \n",
    "above_1 = df2[df2['second_column']>1] # select rows whose 'second_column' value>1\n",
    "above_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optional: dealing with a xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a xlsx\n",
    "y = pd.read_excel('sample.xlsx', sheet_name = 'sheet1')\n",
    "\n",
    "# export a dataframe to a xlsx\n",
    "df.to_excel('pd.xlsx', sheet_name = 'export')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Operation of Environmental Datasets (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip jena_climate_2009_2016.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"jena_climate_2009_2016.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can follow here: https://www.tensorflow.org/tutorials/structured_data/time_series to perform analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data for Project 1 (15 mins)\n",
    "\n",
    "Please don't the data here: https://www.dropbox.com/scl/fi/azzx0olpeyx45rixlsgdn/project_1.csv?rlkey=b4fj8cnmc4ytyezppfbhpky3t&dl=0\n",
    "\n",
    "The definitions of **some** variables are available here: https://www.cesm.ucar.edu/community-projects/lens/data-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"~/Downloads/project_1.csv\") # You may change the path\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Homework\n",
    "\n",
    "- sign up for [Student Developer Pack](https://education.github.com/pack) of the GitHub\n",
    "- think about the (research) question for project 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
